{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids, and separate the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We Separate the dataset\n",
    "from implementations import *\n",
    "\n",
    "tX_list, ids_list, y_list = separate_dataset(tX, ids, y)\n",
    "tX_test_list, ids_test_list = separate_dataset(tX_test, ids_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([1,100,1])\n",
    "print(logsig(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset part 0:\n",
      "     Best degree: 1\n",
      "     Best lambda: 0\n",
      "     Loss: 0.717038664726091\n",
      "Dataset part 1:\n",
      "     Best degree: 3\n",
      "     Best lambda: 0\n",
      "     Loss: 0.8061285859414737\n",
      "Dataset part 2:\n",
      "     Best degree: 5\n",
      "     Best lambda: 0\n",
      "     Loss: 0.759861504623161\n"
     ]
    }
   ],
   "source": [
    "function = ridge_regression\n",
    "degree_vec = []\n",
    "lambda_vec = []\n",
    "for i in range(3):\n",
    "    print('Dataset part {l}:'.format(l = i))\n",
    "    rmse_te, BestDeg, BestLambda = grid_search(y_list[i], tX_list[i], function, True, degrees= range(1, 10))\n",
    "    degree_vec.append(BestDeg)\n",
    "    lambda_vec.append(BestLambda)\n",
    "    print('     Best degree: {d}'.format(d = BestDeg))\n",
    "    print('     Best lambda: {m}'.format(m = BestLambda))\n",
    "    print('     Loss: {lo}'.format(lo = rmse_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[i], True, tX_test_list[i])\n",
    "    w, l = ridge_regression(y_list[i], mat_tX, lambda_vec[i])\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression using gradient descent\n",
    "\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 50\n",
    "gamma = 3e-7\n",
    "\n",
    "weights, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3396868094770349"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Least squares regression using normal equation\n",
    "weights, loss = least_squares(y, tX)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression using normal equations\n",
    "lambda_ = 1e-3\n",
    "weights, loss = ridge_regression(y, tX, lambda_)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2967432202164457"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression with data augmentation\n",
    "lambda_ = 1e-3\n",
    "mat_tX = build_poly(tX, 5)\n",
    "weights, loss = ridge_regression(y, mat_tX, lambda_)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression with separated data\n",
    "lambda_ = 1e-3\n",
    "weights_list, loss_list = separated_train(tX_list, y_list, ridge_regression, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression on separated datset with data augmentation\n",
    "lambda_ = 1e-3\n",
    "mat_tX_list = build_poly_separated(tX_list, 3)\n",
    "# weights, loss = ridge_regression(y_list[0], mat_tX_list[0], lambda_)\n",
    "\n",
    "weights_list, loss_list = separated_train(mat_tX_list, y_list, ridge_regression, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=69254.41425128403\n",
      "Current iteration=100, loss=81449.71895804847\n",
      "Current iteration=200, loss=80696.63673349045\n",
      "Current iteration=300, loss=80592.32343246232\n",
      "Current iteration=400, loss=80576.40882777364\n",
      "Current iteration=500, loss=80573.89748207579\n",
      "Current iteration=600, loss=80573.49583033338\n",
      "Current iteration=700, loss=80573.43125526051\n",
      "Current iteration=800, loss=80573.42085238648\n",
      "Current iteration=900, loss=80573.41917522243\n",
      "Current iteration=1000, loss=80573.4189047484\n",
      "Current iteration=1100, loss=80573.41886112426\n",
      "Current iteration=1200, loss=80573.41885408778\n",
      "Current iteration=1300, loss=80573.41885295244\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\TEMP/ipykernel_17860/520071991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmat_tX_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0minitial_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat_tX_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat_tX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mweights_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmat_tX_test_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX_test_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\EPFL\\MA3\\ML\\projects\\scripts\\implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[1;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m# get loss and update w.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_by_gradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;31m# log info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\EPFL\\MA3\\ML\\projects\\scripts\\implementations.py\u001b[0m in \u001b[0;36mlearning_by_gradient_descent\u001b[1;34m(y, tx, w, gamma)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \"\"\"\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_entropy_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\EPFL\\MA3\\ML\\projects\\scripts\\implementations.py\u001b[0m in \u001b[0;36mcross_entropy_loss\u001b[1;34m(y, tx, w)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;34m\"\"\"compute the loss: negative log likelihood.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\EPFL\\MA3\\ML\\projects\\scripts\\implementations.py\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;34m\"\"\"apply the sigmoid function on t.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0msigm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msigm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights_list = []\n",
    "max_iters = 1500\n",
    "gamma = 1e-4\n",
    "mat_tX_test_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    mat_tX_list = build_poly(tX_list[i], 1)\n",
    "    initial_w = np.zeros((mat_tX_list.shape[1], 1))\n",
    "    w, _ = logistic_regression(np.where(y_list[i] == -1, 0, y_list[i]), mat_tX_list, initial_w, max_iters, gamma)\n",
    "    weights_list.append(w)\n",
    "    mat_tX_test_list.append(tX_test_list[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop\n",
      "Current iteration=0, loss=0.6931471805599453\n",
      "Current iteration=100, loss=0.4113189531633205\n",
      "Current iteration=200, loss=0.40245053711610385\n",
      "Current iteration=300, loss=0.39846170643784407\n",
      "Current iteration=400, loss=0.3963358082071025\n",
      "Current iteration=500, loss=0.3951085013315714\n",
      "Current iteration=600, loss=0.3943734349848903\n",
      "Current iteration=700, loss=0.39392428311126426\n",
      "Current iteration=800, loss=0.39364546656383537\n",
      "Current iteration=900, loss=0.393470426463399\n",
      "Current iteration=1000, loss=0.39335962140466646\n",
      "Current iteration=1100, loss=0.3932890270648617\n",
      "Current iteration=1200, loss=0.3932438196109097\n",
      "Current iteration=1300, loss=0.39321474827185166\n",
      "Current iteration=1400, loss=0.3931959893140119\n",
      "Current iteration=1500, loss=0.3931838504861644\n",
      "Current iteration=1600, loss=0.3931759772765289\n",
      "Current iteration=1700, loss=0.39317086099812804\n",
      "Current iteration=1800, loss=0.3931675310683055\n",
      "Current iteration=1900, loss=0.393165361008756\n",
      "Current iteration=2000, loss=0.39316394533701887\n",
      "0.393163615694024\n",
      "loop\n",
      "Current iteration=0, loss=0.6931471805599453\n",
      "Current iteration=100, loss=0.5456183558753467\n",
      "Current iteration=200, loss=0.542640090106964\n",
      "Current iteration=300, loss=0.5417294814149728\n",
      "Current iteration=400, loss=0.5413751799186768\n",
      "Current iteration=500, loss=0.541224299630684\n",
      "Current iteration=600, loss=0.5411570787774679\n",
      "Current iteration=700, loss=0.541126358040039\n",
      "Current iteration=800, loss=0.5411120990723923\n",
      "Current iteration=900, loss=0.5411054156865315\n",
      "Current iteration=1000, loss=0.5411022632333146\n",
      "Current iteration=1100, loss=0.5411007701077514\n",
      "0.5411007501516861\n",
      "loop\n",
      "Current iteration=0, loss=0.6931471805599453\n",
      "Current iteration=100, loss=0.5326486054150066\n",
      "Current iteration=200, loss=0.5288858191543908\n",
      "Current iteration=300, loss=0.5278401105486227\n",
      "Current iteration=400, loss=0.527469643681758\n",
      "Current iteration=500, loss=0.5273231786681799\n",
      "Current iteration=600, loss=0.5272610514698876\n",
      "Current iteration=700, loss=0.5272333092923251\n",
      "Current iteration=800, loss=0.5272204396337595\n",
      "Current iteration=900, loss=0.5272143005038438\n",
      "Current iteration=1000, loss=0.5272113129336911\n",
      "Current iteration=1100, loss=0.5272098385078026\n",
      "0.5272097983181239\n"
     ]
    }
   ],
   "source": [
    "#Log Reg Pen\n",
    "\n",
    "\n",
    "degree_vec = [1]\n",
    "lambda_vec = [1e-04]\n",
    "gamma_vec = [5e-1]\n",
    "\n",
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "max_iter= 10000\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"loop\")\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[0], False, tX_test_list[i])\n",
    "    initial_w = np.zeros((mat_tX.shape[1], 1))\n",
    "    l, w = logistic_regression_penalized_gradient_descent(y_list[i], mat_tX, initial_w, max_iter, gamma_vec[0], lambda_vec[0])\n",
    "    print(l)\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.177408495127267\n",
      "1.177408495127272\n",
      "1.1774084951273638\n",
      "1.1774084951289836\n",
      "1.177408495157809\n",
      "Done Lambda\n",
      "1.1765167394701652\n",
      "1.1765167420777516\n",
      "1.176516788446237\n",
      "1.1765176124801733\n",
      "1.176532100751031\n",
      "Done Lambda\n",
      "1.1646436065705017\n",
      "1.164644132300932\n",
      "1.1646534775425248\n",
      "1.1648184870731462\n",
      "1.167388924284218\n",
      "Done Lambda\n",
      "1.1525420339259302\n",
      "1.1524860855055388\n",
      "1.1515190450080341\n",
      "1.1411045000151345\n",
      "1.1602323851477754\n",
      "Done Lambda\n",
      "1.2408625466337808\n",
      "1.239092894251509\n",
      "1.214263200874192\n",
      "1.1401401644257123\n",
      "9.477735123546426\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "1.1765720786783482\n",
      "1.1765720788149803\n",
      "1.1765720812445852\n",
      "1.1765721244481846\n",
      "1.1765728922355547\n",
      "Done Lambda\n",
      "1.1650414158606823\n",
      "1.165041448547696\n",
      "1.1650420297956672\n",
      "1.1650523601387257\n",
      "1.1652342188745908\n",
      "Done Lambda\n",
      "1.1118639827540948\n",
      "1.1118264475183632\n",
      "1.111849143750461\n",
      "1.1120941469145553\n",
      "1.1176618481577314\n",
      "Done Lambda\n",
      "1.2436639253163724\n",
      "1.2434984078734155\n",
      "1.2399162409450997\n",
      "1.1936669599245986\n",
      "1.1129367543444302\n",
      "Done Lambda\n",
      "1.5354946042614872\n",
      "1.5342811451391407\n",
      "1.526594130946801\n",
      "1.6247546404219102\n",
      "37.199779076938256\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "1.178666379796548\n",
      "1.1786663795104966\n",
      "1.1786663744238137\n",
      "1.1786662839724884\n",
      "1.1786646768103304\n",
      "Done Lambda\n",
      "1.2019203045712974\n",
      "1.2019215402770906\n",
      "1.201918781380845\n",
      "1.2018911904329155\n",
      "1.2014741554193795\n",
      "Done Lambda\n",
      "1.2589231214595562\n",
      "1.258901438433075\n",
      "1.2585161218067231\n",
      "1.2514679449740247\n",
      "1.1556426319926416\n",
      "Done Lambda\n",
      "2.5494456624072614\n",
      "2.739881983655507\n",
      "2.5562602857535057\n",
      "2.395849473617208\n",
      "1.512737524606558\n",
      "Done Lambda\n",
      "8.651700202440589\n",
      "8.312640242060894\n",
      "6.2943361489116665\n",
      "9.047699928476506\n",
      "126.17780892399264\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "2.0396580747960815\n",
      "2.0396579398728454\n",
      "2.039655543786417\n",
      "2.039809313874297\n",
      "2.04111176610785\n",
      "Done Lambda\n",
      "4.094555900121593\n",
      "4.094548918345094\n",
      "4.09435924999742\n",
      "4.0920965590816945\n",
      "4.052231901464641\n",
      "Done Lambda\n",
      "18.64892666442655\n",
      "18.648511095101885\n",
      "18.69986245036368\n",
      "17.2968546791773\n",
      "14.04160070515299\n",
      "Done Lambda\n",
      "66.2660181271673\n",
      "66.21556916467449\n",
      "65.35089610525496\n",
      "56.74206314397829\n",
      "22.641912091985354\n",
      "Done Lambda\n",
      "261.9568702944152\n",
      "317.70264311819557\n",
      "233.0954439760325\n",
      "107.39277612179536\n",
      "2591.3190540537544\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "Done Deg\n",
      "(array([1]), array([2]), array([1]))\n",
      "1.1118264475183632\n",
      "1.1774095040074133\n",
      "1.1774095040074146\n",
      "1.177409504007445\n",
      "1.1774095040079957\n",
      "1.1774095040177808\n",
      "Done Lambda\n",
      "1.1771131484819874\n",
      "1.1771131493296478\n",
      "1.1771131644028177\n",
      "1.17711343228052\n",
      "1.1771181439830003\n",
      "Done Lambda\n",
      "1.1745012036297162\n",
      "1.1745012419588137\n",
      "1.1745019250031286\n",
      "1.174514516508074\n",
      "1.1748257580848156\n",
      "Done Lambda\n",
      "1.2003651034876097\n",
      "1.200311706595937\n",
      "1.1993807448265208\n",
      "1.1874740122025065\n",
      "1.1736959457923697\n",
      "Done Lambda\n",
      "1.2541662152523763\n",
      "1.2533011976220914\n",
      "1.2402836006204183\n",
      "1.190702924634889\n",
      "11.249769028404707\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "1.177398217519495\n",
      "1.1773982175195339\n",
      "1.1773982175202364\n",
      "1.177398217532764\n",
      "1.1773982177555318\n",
      "Done Lambda\n",
      "1.172004159158895\n",
      "1.1720041723431573\n",
      "1.172004406789644\n",
      "1.1720085738491393\n",
      "1.172082029262511\n",
      "Done Lambda\n",
      "1.1656958763319112\n",
      "1.1656949467001136\n",
      "1.1656784426475926\n",
      "1.1653934850507153\n",
      "1.1624006232371291\n",
      "Done Lambda\n",
      "1.2994789912863607\n",
      "1.2993126024720951\n",
      "1.2963978274458687\n",
      "1.2560883401279288\n",
      "1.1656638317943648\n",
      "Done Lambda\n",
      "2.3038493189271803\n",
      "2.3031213039207827\n",
      "2.2901277728062452\n",
      "2.1299936512710875\n",
      "38.22037832554862\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "1.1775199238980631\n",
      "1.1775199237642158\n",
      "1.1775199213840488\n",
      "1.1775198790610046\n",
      "1.1775191273907868\n",
      "Done Lambda\n",
      "1.1822480964391613\n",
      "1.1822480709509897\n",
      "1.182247617727299\n",
      "1.182239566732672\n",
      "1.1820990775100115\n",
      "Done Lambda\n",
      "1.1742765330364433\n",
      "1.1742759490226677\n",
      "1.1742655855024648\n",
      "1.1740881073152603\n",
      "1.17256672199922\n",
      "Done Lambda\n",
      "1.5450642643362527\n",
      "1.614493206847558\n",
      "1.5145189867988713\n",
      "1.6298514398951205\n",
      "1.5543740312348333\n",
      "Done Lambda\n",
      "4.461091198029515\n",
      "5.461572993798596\n",
      "4.658930530137031\n",
      "6.158875691309855\n",
      "69.38895613418944\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "1.1875731574583857\n",
      "1.187573155828174\n",
      "1.1875731268385392\n",
      "1.18757261134755\n",
      "1.1875634526023826\n",
      "Done Lambda\n",
      "1.2089539847150261\n",
      "1.2095573676156615\n",
      "1.21654996768091\n",
      "1.2347404703065117\n",
      "1.1986626652075827\n",
      "Done Lambda\n",
      "2.255107783494369\n",
      "1.934917505683101\n",
      "2.21744070432819\n",
      "1.9057107286250135\n",
      "2.2209100964537645\n",
      "Done Lambda\n",
      "7.672119689037483\n",
      "9.191293918000063\n",
      "8.270653384566472\n",
      "6.680019225963103\n",
      "8.152552144929649\n",
      "Done Lambda\n",
      "35.30812640174602\n",
      "29.121202435329295\n",
      "37.003590675229724\n",
      "33.474017089146805\n",
      "455.7626315346903\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "Done Deg\n",
      "(array([1]), array([2]), array([4]))\n",
      "1.1624006232371291\n",
      "1.1774099524372346\n",
      "1.177409952437235\n",
      "1.177409952437239\n",
      "1.1774099524373158\n",
      "1.1774099524386339\n",
      "Done Lambda\n",
      "1.1773844457365195\n",
      "1.1773844457652451\n",
      "1.1773844462760463\n",
      "1.17738445536821\n",
      "1.177384619697419\n",
      "Done Lambda\n",
      "1.1806684634583957\n",
      "1.1806681019274763\n",
      "1.1806616802816698\n",
      "1.1805497865479468\n",
      "1.179130206042831\n",
      "Done Lambda\n",
      "1.2754187665462784\n",
      "1.2753101212620985\n",
      "1.2734069179395309\n",
      "1.2469927504071445\n",
      "1.1826802863153558\n",
      "Done Lambda\n",
      "1.343404813306791\n",
      "1.342280701304585\n",
      "1.3257290021284411\n",
      "1.2537197579607193\n",
      "12.201853689750005\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "1.1774070041857334\n",
      "1.1774070041857443\n",
      "1.1774070041859257\n",
      "1.1774070041891247\n",
      "1.1774070042460243\n",
      "Done Lambda\n",
      "1.1768997424010215\n",
      "1.1768997412694904\n",
      "1.1768997211505794\n",
      "1.1768993642888852\n",
      "1.1768933005766538\n",
      "Done Lambda\n",
      "1.209545987074916\n",
      "1.2095432393578762\n",
      "1.2094944230195939\n",
      "1.2086406270488115\n",
      "1.1971493510631255\n",
      "Done Lambda\n",
      "1.4009249182362415\n",
      "1.4007278661347975\n",
      "1.3972732890549415\n",
      "1.3487251108640024\n",
      "1.20985166284177\n",
      "Done Lambda\n",
      "2.365300832718482\n",
      "2.3637253644964913\n",
      "2.343423538705007\n",
      "2.321098891719391\n",
      "40.408486818791815\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "1.1790171349291974\n",
      "1.1790171344689222\n",
      "1.1790171262839668\n",
      "1.1790169807402504\n",
      "1.1790143949971315\n",
      "Done Lambda\n",
      "1.2048977388453455\n",
      "1.2048976367231445\n",
      "1.2048958207933853\n",
      "1.2048635563867867\n",
      "1.2042985271496518\n",
      "Done Lambda\n",
      "1.2794943647461838\n",
      "1.2794894351694188\n",
      "1.2794018552108788\n",
      "1.277869942821135\n",
      "1.2571145118521823\n",
      "Done Lambda\n",
      "1.5402418613581295\n",
      "1.5258227237669648\n",
      "1.5754759508613174\n",
      "1.4995192248418505\n",
      "1.5233380744430154\n",
      "Done Lambda\n",
      "5.077257127199839\n",
      "4.472697107985547\n",
      "4.756051765768602\n",
      "5.7417400437812915\n",
      "88.48951296048257\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "1.2181893240319497\n",
      "1.2181893175628562\n",
      "1.2181892025245886\n",
      "1.2181871569167158\n",
      "1.2181508100003542\n",
      "Done Lambda\n",
      "1.278135632877254\n",
      "1.2782680088510905\n",
      "1.2760953851128571\n",
      "1.2803091926080123\n",
      "1.2764785380731078\n",
      "Done Lambda\n",
      "1.784849673012767\n",
      "2.233082392994314\n",
      "2.3820999546178925\n",
      "2.2362265751308747\n",
      "2.1383694776111777\n",
      "Done Lambda\n",
      "6.521932471903636\n",
      "7.233116957045408\n",
      "8.889383871086272\n",
      "6.975901874965135\n",
      "8.955648826924472\n",
      "Done Lambda\n",
      "43.35339588225268\n",
      "31.707076647918928\n",
      "35.76867149768483\n",
      "30.704453316123438\n",
      "614.1155704234892\n",
      "Done Lambda\n",
      "Done Gamma\n",
      "Done Deg\n",
      "(array([1]), array([1]), array([4]))\n",
      "1.1768933005766538\n"
     ]
    }
   ],
   "source": [
    "degrees = range(1, 5)\n",
    "lambdas = np.logspace(-5, 0, 5)\n",
    "gammas = np.logspace(-5, 0, 5)\n",
    "\n",
    "degree_vec = []\n",
    "lambda_vec = []\n",
    "gamma_vec = []\n",
    "\n",
    "for i in range(3):\n",
    "    rmse_te, BestDeg, BestLambda, BestGamma = grid_search_for_log_reg(y_list[i], tX_list[i], True, 4, degrees, lambdas, gammas)\n",
    "    degree_vec.append(BestDeg)\n",
    "    lambda_vec.append(BestLambda)\n",
    "    gamma_vec.append(BestGamma)\n",
    "    print(rmse_te)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(degree_vec)\n",
    "print(gamma_vec)\n",
    "print(lambda_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "max_iter = 5000\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"loop\")\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[i], True, tX_test_list[i])\n",
    "    initial_w = np.zeros((mat_tX.shape[1], 1))\n",
    "    l, w = logistic_regression_penalized_gradient_descent(y_list[i], mat_tX, initial_w, max_iter, gamma_vec[i], lambda_vec[i])\n",
    "    print(l)\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 240)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (568238,240) and (4,30) not aligned: 240 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\TEMP/ipykernel_5056/3670384538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmat_tX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat_tX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat_tX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcreate_csv_submission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\EPFL\\MA3\\ML\\projects\\scripts\\proj1_helpers.py\u001b[0m in \u001b[0;36mpredict_labels\u001b[1;34m(weights, data)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (568238,240) and (4,30) not aligned: 240 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Data augmentation\n",
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "mat_tX_test = build_poly(tX_test, 3)\n",
    "print(mat_tX_test.shape)\n",
    "y_pred = predict_labels(weights, mat_tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separated dataset\n",
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "\n",
    "tX_test_list, ids_test_list = separate_dataset(tX_test, ids_test)\n",
    "y_pred_list = separated_eval(weights_list, tX_test_list)\n",
    "\n",
    "y_pred = np.concatenate((y_pred_list[0], y_pred_list[1], y_pred_list[2], y_pred_list[3]))\n",
    "ids_test_sub = np.concatenate((ids_test_list[0], ids_test_list[1], ids_test_list[2], ids_test_list[3]))\n",
    "\n",
    "create_csv_submission(ids_test_sub, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and separated dataset\n",
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "\n",
    "tX_test_list, ids_test_list = separate_dataset(tX_test, ids_test)   #separate dateset\n",
    "\n",
    "mat_tX_test_list = []\n",
    "\n",
    "# for i in range(4):\n",
    "#     print(i)\n",
    "#     mat_tX_test = build_poly(tX_test_list[i], degree_vec[i])\n",
    "#     mat_tX_test_list.append(mat_tX_test)\n",
    "\n",
    "# mat_tX_test_list = build_poly_separated(tX_test_list, 3)            #data augmentation\n",
    "y_pred_list = separated_eval(weights_list, mat_tX_test_list)        #prediction\n",
    "\n",
    "y_pred = np.concatenate((y_pred_list[0], y_pred_list[1], y_pred_list[2], y_pred_list[3]))\n",
    "ids_test_sub = np.concatenate((ids_test_list[0], ids_test_list[1], ids_test_list[2], ids_test_list[3]))\n",
    "\n",
    "create_csv_submission(ids_test_sub, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "\n",
    "y_pred_list = separated_eval(weights_list, mat_tX_test_list) \n",
    "\n",
    "y_pred = np.concatenate((y_pred_list[0], y_pred_list[1], y_pred_list[2]))\n",
    "ids_test_sub = np.concatenate((ids_test_list[0], ids_test_list[1], ids_test_list[2]))\n",
    "\n",
    "OUTPUT_PATH = 'result.csv'\n",
    "create_csv_submission(ids_test_sub, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

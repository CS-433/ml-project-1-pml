{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/lkxf5xgn5qd0l88pblwqxc6h0000gn/T/ipykernel_37732/1938088011.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  corr= num/den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 3, 5], [0, 6, 9], [1, 0, 2], [1, 3, 6], [1, 3, 18], [1, 3, 21], [1, 6, 18], [1, 6, 21], [1, 18, 21], [2, 0, 2], [2, 3, 9], [2, 4, 5], [2, 9, 21], [2, 9, 22], [2, 9, 28], [2, 21, 28], [2, 22, 28]]\n"
     ]
    }
   ],
   "source": [
    "#Check data\n",
    "tX_list, ids_list = separate_dataset(tX, ids)\n",
    "index=[]\n",
    "for seT in range(len(tX_list)-1):\n",
    "    for indexX, column in enumerate(tX_list[seT].T):\n",
    "        x_= np.mean(column)\n",
    "        for indexY, column2 in enumerate(tX_list[seT].T):\n",
    "            y_= np.mean(column2)\n",
    "            num=np.dot((column - x_),(column2 - y_))\n",
    "            den= np.sqrt(np.dot(column - x_,column - x_)*np.dot(column2 - y_,column2 - y_))\n",
    "            corr= num/den\n",
    "            if corr> 0.8 and indexX!= indexY and indexX< indexY:\n",
    "                index.append([seT,indexX, indexY])\n",
    "\n",
    "print(index)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_k_indices() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n2/lkxf5xgn5qd0l88pblwqxc6h0000gn/T/ipykernel_37732/1557179070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mBestLambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#x_tr, x_te, y_tr, y_te= split_data(tX, y, ratio_train, seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mk_indices\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mbuild_k_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mrmse_te_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mBestLambdaForDeg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: build_k_indices() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# Ridge regression with K-fold\n",
    "k_fold= 4\n",
    "degrees = range(1, 3)\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "seed = 1\n",
    "#ratio_train = 0.7\n",
    "\n",
    "rmse_te = 0\n",
    "BestDeg=0\n",
    "BestLambda=0\n",
    "#x_tr, x_te, y_tr, y_te= split_data(tX, y, ratio_train, seed)\n",
    "k_indices =build_k_indices(y, k_fold, seed)\n",
    "rmse_te_tmp = []\n",
    "BestLambdaForDeg=[]\n",
    "for index_degree, degree in enumerate(degrees):\n",
    "    rmse_te_tmp2 = []\n",
    "    for index_lambda, lambda_ in enumerate(lambdas):\n",
    "        loss_te_tmp=0\n",
    "        for k in range(k_fold):\n",
    "            _, loss_te, w=cross_validation(y, tX, k_indices, k, lambda_, degree)\n",
    "            loss_te_tmp= loss_te_tmp+loss_te\n",
    "        loss_te_tmp=loss_te_tmp/k_fold\n",
    "        rmse_te_tmp2.append(np.sqrt(2*loss_te_tmp))\n",
    "    rmse_te_tmp.append(min(rmse_te_tmp2))\n",
    "    BestLambdaForDeg.append(lambdas[np.argmin(rmse_te_tmp2)])\n",
    "BestDeg=degrees[np.argmin(rmse_te_tmp)]\n",
    "BestLambda= BestLambdaForDeg[np.argmin(rmse_te_tmp)]\n",
    "rmse_te=min(rmse_te_tmp)\n",
    "\n",
    "\n",
    "loss=rmse_te\n",
    "print(BestDeg)\n",
    "print(BestLambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33968680947709307"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Least squares regression using normal equation\n",
    "weight, loss = least_squares(y, tX)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33944686042508954"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression using normal equations\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "lambda_ = BestLambda\n",
    "tx=build_poly(tX,BestDeg)\n",
    "\n",
    "weights, loss = ridge_regression(y, tx, lambda_)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset part 0:\n",
      "     Best degree: 1\n",
      "     Best lambda: 3.359818286283781e-07\n",
      "     Loss: 0.7177556387376729\n",
      "Dataset part 1:\n",
      "     Best degree: 6\n",
      "     Best lambda: 0.00026366508987303583\n",
      "     Loss: 0.7903514696724503\n",
      "Dataset part 2:\n",
      "     Best degree: 5\n",
      "     Best lambda: 1e-07\n",
      "     Loss: 0.7625660276943759\n"
     ]
    }
   ],
   "source": [
    "#Importation of train and test data:\n",
    "\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "#Separate Data Set\n",
    "from implementations import *\n",
    "\n",
    "tX_list, ids_list, y_list = separate_dataset(tX, ids, y)\n",
    "tX_test_list, ids_test_list = separate_dataset(tX_test, ids_test)\n",
    "\n",
    "\n",
    "\n",
    "#Grid Search of param\n",
    "function = ridge_regression\n",
    "degree_vec = []\n",
    "lambda_vec = []\n",
    "for i in range(3):\n",
    "    print('Dataset part {l}:'.format(l = i))\n",
    "    rmse_te, BestDeg, BestLambda = grid_search(y_list[i], tX_list[i], function, True)\n",
    "    degree_vec.append(BestDeg)\n",
    "    lambda_vec.append(BestLambda)\n",
    "    print('     Best degree: {d}'.format(d = BestDeg))\n",
    "    print('     Best lambda: {m}'.format(m = BestLambda))\n",
    "    print('     Loss: {lo}'.format(lo = rmse_te))\n",
    "\n",
    "\n",
    "\n",
    "#Training\n",
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[i], True, tX_test_list[i])\n",
    "    w, l = ridge_regression(y_list[i], mat_tX, lambda_vec[i])\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test_poly=build_poly(tX_test,BestDeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_poly)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission with separate data, grid search and ridge of log\n",
    "\n",
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "\n",
    "# mat_tX_test_list = build_poly_separated(tX_test_list, 3)            #data augmentation\n",
    "y_pred_list = separated_eval(weights_list, mat_tX_test_list)        #prediction\n",
    "\n",
    "y_pred = np.concatenate((y_pred_list[0], y_pred_list[1], y_pred_list[2]))\n",
    "ids_test_sub = np.concatenate((ids_test_list[0], ids_test_list[1], ids_test_list[2]))\n",
    "\n",
    "create_csv_submission(ids_test_sub, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

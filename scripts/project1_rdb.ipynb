{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/lib/histograms.py:906: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 17 list[Polygon] objects>)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "tX_list, ids_list = separate_dataset(tX, ids)\n",
    "column = tX_list[0][np.all(y==1),0]\n",
    "plt.hist(column,histtype= 'step', density=True)\n",
    "#for indexX, column in enumerate(tX_list[0].T):\n",
    "    #histo=np.histogram(column[0].T)\n",
    "    #sns.displot(column)\n",
    "    #plt.hist(histo,histtype= 'step', density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2, 4], [1, 0, 2], [1, 3, 5], [2, 17, 20], [3, 0, 2], [3, 3, 6], [3, 3, 18], [3, 3, 21], [3, 6, 18], [3, 6, 21], [3, 18, 21], [4, 8, 27], [4, 21, 27], [5, 0, 2], [5, 9, 21], [5, 9, 22], [5, 9, 28], [5, 21, 28], [5, 22, 28]]\n"
     ]
    }
   ],
   "source": [
    "#Check data\n",
    "tX_list, ids_list = separate_dataset(tX, ids)\n",
    "index=[]\n",
    "for seT in range(len(tX_list)):\n",
    "    for indexX, column in enumerate(tX_list[seT].T):\n",
    "        x_= np.mean(column)\n",
    "        for indexY, column2 in enumerate(tX_list[seT].T):\n",
    "            y_= np.mean(column2)\n",
    "            num=np.dot((column - x_),(column2 - y_))\n",
    "            den= np.sqrt(np.dot(column - x_,column - x_)*np.dot(column2 - y_,column2 - y_))\n",
    "            corr= num/den\n",
    "            if corr> 0.85 and indexX!= indexY and indexX< indexY:\n",
    "                index.append([seT,indexX, indexY])\n",
    "\n",
    "print(index)\n",
    "      \n",
    "def datamodif(tX_list, log=False):\n",
    "    tX_list[0]=np.delete(tX_list[0], [4], axis=1)\n",
    "    print(tX_list[0].shape)\n",
    "    long_tail = [0, 1, 2, 3, 4, 5, 6, 7, 10, 13, 15]\n",
    "    tX_list[0][:, long_tail]= np.sqrt(tX_list[0][:, long_tail])\n",
    "    if log:\n",
    "        normalize(tX_list[0])\n",
    "    else:\n",
    "        standardize(tX_list[0])\n",
    "\n",
    "    tX_list[1]=np.delete(tX_list[1], [2,5], axis=1)\n",
    "    print(tX_list[1].shape)\n",
    "    long_tail = [0, 1, 4, 5, 7, 10, 13, 7, 13, 15]\n",
    "    tX_list[1][:, long_tail]= np.sqrt(tX_list[1][:, long_tail])\n",
    "    #tX_list[1][:, 6]= np.where(tX_list[1][:, 6]> 0.5, 1, 0)\n",
    "    if log:\n",
    "        normalize(tX_list[1])\n",
    "    else:\n",
    "        standardize(tX_list[1])\n",
    "\n",
    "    tX_list[2]=np.delete(tX_list[2], [20], axis=1)\n",
    "    print(tX_list[2].shape)\n",
    "    long_tail = [0, 1, 2, 3, 4, 5, 6, 8, 11, 14, 16, 17]\n",
    "    tX_list[2][:, long_tail]= np.sqrt(tX_list[2][:, long_tail])\n",
    "    #tX_list[2][:, 7]= np.where(tX_list[2][:, 7]> 0.5, 1, 0)\n",
    "    if log:\n",
    "        normalize(tX_list[2])\n",
    "    else:\n",
    "        standardize(tX_list[2])\n",
    "\n",
    "    tX_list[3]=np.delete(tX_list[3], [3,6,18], axis=1)\n",
    "    print(tX_list[3].shape)\n",
    "    long_tail = [0, 1, 2, 3, 4, 5, 7, 10, 13, 15, 18]\n",
    "    tX_list[3][:, long_tail]= np.sqrt(tX_list[3][:, long_tail])\n",
    "    #tX_list[3][:, 6]= np.where(tX_list[3][:, 6]> 0.5, 1, 0)\n",
    "    if log:\n",
    "        normalize(tX_list[3])\n",
    "    else:\n",
    "        standardize(tX_list[3])\n",
    "\n",
    "    tX_list[4]=np.delete(tX_list[4], [27], axis=1)\n",
    "    print(tX_list[4].shape)\n",
    "    long_tail = [0, 1, 2, 3, 4, 6, 7, 8, 9, 12, 15, 18, 20, 21]\n",
    "    tX_list[4][:, long_tail]= np.sqrt(tX_list[4][:, long_tail])\n",
    "    #tX_list[4][:, 11]= np.where(tX_list[4][:, 11]> 0.5, 1, 0)\n",
    "    #tX_list[4][:, 10]= np.where(tX_list[4][:, 10]> 0.5, 1, 0)\n",
    "    if log:\n",
    "        normalize(tX_list[4])\n",
    "    else:\n",
    "        standardize(tX_list[4])\n",
    "\n",
    "    tX_list[5]=np.delete(tX_list[5], [2,9,28], axis=1)\n",
    "    print(tX_list[5].shape)\n",
    "    long_tail = [0, 1, 2, 3, 4, 6, 7, 8, 11, 14, 17, 19, 20, 23]\n",
    "    tX_list[5][:, long_tail]= np.sqrt(tX_list[5][:, long_tail])\n",
    "    #tX_list[5][:, 9]= np.where(tX_list[5][:, 9]> 0.5, 1, 0)\n",
    "    #tX_list[5][:, 10]= np.where(tX_list[5][:, 10]> 0.5, 1, 0)\n",
    "    if log:\n",
    "        normalize(tX_list[5])\n",
    "    else:\n",
    "        standardize(tX_list[5])\n",
    "\n",
    "    return tX_list\n",
    "\n",
    "#import seaborn as sns\n",
    "#for indexX, column in enumerate(tX_list[5].T):\n",
    "#    sns.displot(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26123, 16)\n",
      "(73790, 16)\n",
      "(7562, 20)\n",
      "(69982, 19)\n",
      "(4429, 27)\n",
      "(68114, 26)\n",
      "(59263, 16)\n",
      "(168195, 16)\n",
      "(17243, 20)\n",
      "(158095, 19)\n",
      "(9982, 27)\n",
      "(155460, 26)\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "from implementations import *\n",
    "\n",
    "tX_list, ids_list, y_list = separate_dataset(tX, ids, y)\n",
    "tX_test_list, ids_test_list = separate_dataset(tX_test, ids_test)\n",
    "\n",
    "tX_list = datamodif(tX_list)\n",
    "tX_test_list = datamodif(tX_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset part 0:\n",
      "     Best degree: 5\n",
      "     Best lambda: 6.951927961775591e-13\n",
      "     Loss: 0.41281470964633366\n",
      "Dataset part 1:\n",
      "     Best degree: 19\n",
      "     Best lambda: 2.06913808111479e-07\n",
      "     Loss: 0.7616515593061501\n",
      "Dataset part 2:\n",
      "     Best degree: 4\n",
      "     Best lambda: 7.847599703514607e-08\n",
      "     Loss: 0.5231766428569052\n",
      "Dataset part 3:\n",
      "     Best degree: 7\n",
      "     Best lambda: 3.359818286283788e-11\n",
      "     Loss: 0.8025224676686908\n",
      "Dataset part 4:\n",
      "     Best degree: 9\n",
      "     Best lambda: 1.43844988828766e-06\n",
      "     Loss: 0.5451902719212371\n",
      "Dataset part 5:\n",
      "     Best degree: 7\n",
      "     Best lambda: 2.6366508987303554e-13\n",
      "     Loss: 0.7539102873274455\n"
     ]
    }
   ],
   "source": [
    "#Grid Search Ridge\n",
    "\n",
    "function = ridge_regression\n",
    "degree_vec = []\n",
    "lambda_vec = []\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    print('Dataset part {l}:'.format(l = i))\n",
    "    rmse_te, BestDeg, BestLambda, _ = grid_search(y_list[i], tX_list[i], ridge_regression, log = False, k_fold = 4, degrees = range(1, 20), lambdas = np.logspace(-13, -5, 20), gammas = np.arange(1))\n",
    "    degree_vec.append(BestDeg)\n",
    "    lambda_vec.append(BestLambda)\n",
    "    print('     Best degree: {d}'.format(d = BestDeg))\n",
    "    print('     Best lambda: {m}'.format(m = BestLambda))\n",
    "    print('     Loss: {lo}'.format(lo = rmse_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "\n",
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "\n",
    "for i in range(6):\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[i], False, tX_test_list[i])\n",
    "    w, l = ridge_regression(y_list[i], mat_tX, lambda_vec[i])\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "\n",
    "y_pred_list = separated_eval(weights_list, mat_tX_test_list, False) \n",
    "\n",
    "y_pred = np.concatenate((y_pred_list[0], y_pred_list[1], y_pred_list[2], y_pred_list[3], y_pred_list[4], y_pred_list[5]))\n",
    "ids_test_sub = np.concatenate((ids_test_list[0], ids_test_list[1], ids_test_list[2], ids_test_list[3], ids_test_list[4], ids_test_list[5]))\n",
    "\n",
    "OUTPUT_PATH = 'result.csv'\n",
    "create_csv_submission(ids_test_sub, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26123, 16)\n",
      "(73790, 16)\n",
      "(7562, 20)\n",
      "(69982, 19)\n",
      "(4429, 27)\n",
      "(68114, 26)\n",
      "(59263, 16)\n",
      "(168195, 16)\n",
      "(17243, 20)\n",
      "(158095, 19)\n",
      "(9982, 27)\n",
      "(155460, 26)\n"
     ]
    }
   ],
   "source": [
    "#Load Data for Log\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "from implementations import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset part 0:\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n2/lkxf5xgn5qd0l88pblwqxc6h0000gn/T/ipykernel_73070/527485971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset part {l}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrmse_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBestDeg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBestLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBestGamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgammas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdegree_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBestDeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlambda_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBestLambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(y, tX, function, log, k_fold, degrees, lambdas, gammas)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mloss_te_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                     \u001b[0mloss_te_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_te_tmp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_te\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mrmse_te_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_lambda\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_te_tmp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, k_indices, k, degree, function, args, log)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0minitial_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mloss_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mloss_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_te_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, tx, initial_w, max_iter, lambda_, gamma)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# get loss and update w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mcompute_gradient_log\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gradient_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_sigy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "function = reg_logistic_regression\n",
    "degree_vec = []\n",
    "lambda_vec = []\n",
    "gamma_vec= []\n",
    "\n",
    "for i in range(6):\n",
    "    print('Dataset part {l}:'.format(l = i))\n",
    "    rmse_te, BestDeg, BestLambda, BestGamma = grid_search(y_list[i], tX_list[i], reg_logistic_regression, log = False, k_fold = 4, degrees = range(1,3), lambdas = np.logspace(-15, -6, 8), gammas = np.logspace(-4, 0, 5))\n",
    "    degree_vec.append(BestDeg)\n",
    "    lambda_vec.append(BestLambda)\n",
    "    gamma_vec.append(BestGamma)\n",
    "    print('     Best degree: {d}'.format(d = BestDeg))\n",
    "    print('     Best lambda: {m}'.format(m = BestLambda))\n",
    "    print('     Best gamma: {g}'.format(g = BestGamma))\n",
    "    print('     Loss: {lo}'.format(lo = rmse_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n",
      "treshold\n"
     ]
    }
   ],
   "source": [
    "#Train Logistic\n",
    "from implementations import *\n",
    "\n",
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "max_iter= 5000\n",
    "\n",
    "for i in range(6):\n",
    "    initial_w= np.zeros((tX_list[i].shape[1], 1))\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[i], False, tX_test_list[i])\n",
    "    l, w = reg_logistic_regression(y_list[i], tX_list[i], initial_w, max_iter, lambda_vec[i], gamma_vec[i])\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval Logistic\n",
    "\n",
    "y_pred_list = separated_eval(weights_list, mat_tX_test_list, True) \n",
    "\n",
    "y_pred = np.concatenate((y_pred_list[0], y_pred_list[1], y_pred_list[2], y_pred_list[3], y_pred_list[4], y_pred_list[5]))\n",
    "ids_test_sub = np.concatenate((ids_test_list[0], ids_test_list[1], ids_test_list[2], ids_test_list[3], ids_test_list[4], ids_test_list[5]))\n",
    "\n",
    "OUTPUT_PATH = 'result.csv'\n",
    "create_csv_submission(ids_test_sub, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset part 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/linalg/linalg.py:2158: RuntimeWarning: overflow encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Best degree: 1\n",
      "     Best lambda: 0.0008733261623828437\n",
      "     Loss: 0.7380547288266697\n",
      "Dataset part 1:\n",
      "     Best degree: 5\n",
      "     Best lambda: 0.024118646996409948\n",
      "     Loss: 0.8058598609702398\n",
      "Dataset part 2:\n",
      "     Best degree: 4\n",
      "     Best lambda: 0.005817091329374358\n",
      "     Loss: 0.7826367955518109\n"
     ]
    }
   ],
   "source": [
    "#Importation of train and test data:\n",
    "\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "#Separate Data Set\n",
    "from implementations import *\n",
    "\n",
    "tX_list, ids_list, y_list = separate_dataset(tX, ids, y)\n",
    "tX_test_list, ids_test_list = separate_dataset(tX_test, ids_test)\n",
    "\n",
    "\n",
    "\n",
    "#Grid Search of param\n",
    "function = ridge_regression\n",
    "degree_vec = []\n",
    "lambda_vec = []\n",
    "for i in range(3):\n",
    "    print('Dataset part {l}:'.format(l = i))\n",
    "    rmse_te, BestDeg, BestLambda = grid_search(y_list[i], tX_list[i], function, True)\n",
    "    degree_vec.append(BestDeg)\n",
    "    lambda_vec.append(BestLambda)\n",
    "    print('     Best degree: {d}'.format(d = BestDeg))\n",
    "    print('     Best lambda: {m}'.format(m = BestLambda))\n",
    "    print('     Loss: {lo}'.format(lo = rmse_te))\n",
    "\n",
    "\n",
    "\n",
    "#Training\n",
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[i], True, tX_test_list[i])\n",
    "    w, l = ridge_regression(y_list[i], mat_tX, lambda_vec[i])\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset part 0:\n",
      "Done Lambda\n",
      "Done Lambda\n",
      "Done Lambda\n",
      "Done Lambda\n",
      "Done Lambda\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n2/lkxf5xgn5qd0l88pblwqxc6h0000gn/T/ipykernel_64038/3558008276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset part {l}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mrmse_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBestDeg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBestLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBestGamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_for_log_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdegree_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBestDeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlambda_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBestLambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mgrid_search_for_log_reg\u001b[0;34m(y, tX, log, k_fold, degrees, lambdas, gammas)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mloss_te_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_log_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                     \u001b[0mloss_te_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_te_tmp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_te\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mrmse_te_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_lambda\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_te_tmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mcross_validation_log_len\u001b[0;34m(y, x, k_indices, k, degree, lambda_, gamma, log)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0minitial_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mloss_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_penalized_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression_penalized_gradient_descent\u001b[0;34m(y, tx, initial_w, max_iter, gamma, lambda_)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# get loss and update w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_by_penalized_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;31m# log info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m#if iter % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mlearning_by_penalized_gradient\u001b[0;34m(y, tx, w, gamma, lambda_)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \"\"\"\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenalized_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mpenalized_logistic_regression\u001b[0;34m(y, tx, w, lambda_)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpenalized_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m\"\"\"return the loss, gradient\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36mcross_entropy_loss\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"\"\"compute the loss: negative log likelihood.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cours EPFL MA1/Machine Learning/ml-project-1-pml/scripts/implementations.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"\"\"apply the sigmoid function on t.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msigm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msigm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "#Separate Data Set\n",
    "from implementations import *\n",
    "\n",
    "tX_list, ids_list, y_list = separate_dataset(tX, ids, y)\n",
    "tX_test_list, ids_test_list = separate_dataset(tX_test, ids_test)\n",
    "\n",
    "degree_vec = []\n",
    "lambda_vec = []\n",
    "gamma_vec = []\n",
    "for i in range(3):\n",
    "    print('Dataset part {l}:'.format(l = i))\n",
    "    rmse_te, BestDeg, BestLambda, BestGamma = grid_search_for_log_reg(y_list[i], tX_list[i], False)\n",
    "    degree_vec.append(BestDeg)\n",
    "    lambda_vec.append(BestLambda)\n",
    "    gamma_vec.append(BestGamma)\n",
    "    print('     Best degree: {d}'.format(d = BestDeg))\n",
    "    print('     Best lambda: {m}'.format(m = BestLambda))\n",
    "    print('     Best gamma: {g}'.format(g = BestGamma))\n",
    "    print('     Loss: {lo}'.format(lo = rmse_te))\n",
    "\n",
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "max_iter= 10000\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[i], False, tX_test_list[i])\n",
    "    initial_w = np.zeros((mat_tX.shape[1], 1))\n",
    "    l, w = logistic_regression_penalized_gradient_descent(y_list[i], mat_tX, initial_w, max_iter, gamma_vec[i], lambda_vec[i])\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Data separated\n",
      "loop\n",
      "-64730.23741869711\n",
      "loop\n",
      "-63383.06999684557\n",
      "loop\n",
      "-181.017636445889\n"
     ]
    }
   ],
   "source": [
    "#Log Reg Pen\n",
    "\n",
    "\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "print(\"Data loaded\")\n",
    "\n",
    "\n",
    "#Separate Data Set\n",
    "from implementations import *\n",
    "\n",
    "tX_list, ids_list, y_list = separate_dataset(tX, ids, y)\n",
    "tX_test_list, ids_test_list = separate_dataset(tX_test, ids_test)\n",
    "print(\"Data separated\")\n",
    "\n",
    "degree_vec = [1 , 4 , 5]\n",
    "lambda_vec = [1e-05 , 1e-04 , 1e-04]\n",
    "gamma_vec = [8.65e-10 , 1.9e-9, 1e-9]\n",
    "\n",
    "weights_list = []\n",
    "loss_list = []\n",
    "mat_tX_test_list = []\n",
    "max_iter= 10000\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"loop\")\n",
    "    mat_tX, mat_tX_test = build_poly_log(tX_list[i], degree_vec[i], False, tX_test_list[i])\n",
    "    initial_w = np.zeros((mat_tX.shape[1], 1))\n",
    "    l, w = logistic_regression_penalized_gradient_descent(y_list[i], mat_tX, initial_w, max_iter, gamma_vec[i], lambda_vec[i])\n",
    "    print(l)\n",
    "    weights_list.append(w)\n",
    "    loss_list.append(l)\n",
    "    mat_tX_test_list.append(mat_tX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test_poly=build_poly(tX_test,BestDeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_poly)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission with separate data, grid search and ridge of log\n",
    "\n",
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "\n",
    "# mat_tX_test_list = build_poly_separated(tX_test_list, 3)            #data augmentation\n",
    "y_pred_list = separated_eval(weights_list, mat_tX_test_list)        #prediction\n",
    "\n",
    "y_pred = np.concatenate((y_pred_list[0], y_pred_list[1], y_pred_list[2]))\n",
    "ids_test_sub = np.concatenate((ids_test_list[0], ids_test_list[1], ids_test_list[2]))\n",
    "\n",
    "create_csv_submission(ids_test_sub, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

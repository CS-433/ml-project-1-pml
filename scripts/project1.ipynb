{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from functions import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): loss=0.5, w0=3.229994853120003e-05, w1=-8.185259581200002e-06\n",
      "Gradient Descent(1/49): loss=0.4684975020271792, w0=4.737735523736882e-05, w1=-8.288091556578185e-06\n",
      "Gradient Descent(2/49): loss=0.4513712748460005, w0=7.2830273140742e-05, w1=-1.4153561994065591e-05\n",
      "Gradient Descent(3/49): loss=0.44178360296424807, w0=8.891083213320669e-05, w1=-1.5810090997021512e-05\n",
      "Gradient Descent(4/49): loss=0.43617479340076165, w0=0.00010996659128578852, w1=-2.044325562731981e-05\n",
      "Gradient Descent(5/49): loss=0.4326884948512339, w0=0.0001257725187546787, w1=-2.2878720716603202e-05\n",
      "Gradient Descent(6/49): loss=0.4303539841023341, w0=0.00014379601356697091, w1=-2.684601115822895e-05\n",
      "Gradient Descent(7/49): loss=0.4286614226647361, w0=0.00015875071836384647, w1=-2.966032971941444e-05\n",
      "Gradient Descent(8/49): loss=0.4273411475179239, w0=0.00017453053731563144, w1=-3.3257608571233524e-05\n",
      "Gradient Descent(9/49): loss=0.4262489193466734, w0=0.00018840941370472445, w1=-3.624498374587162e-05\n",
      "Gradient Descent(10/49): loss=0.4253062112549615, w0=0.00020242433054509372, w1=-3.9627548018196366e-05\n",
      "Gradient Descent(11/49): loss=0.4244691000973839, w0=0.0002151757292747253, w1=-4.268286455550896e-05\n",
      "Gradient Descent(12/49): loss=0.42371203005243574, w0=0.0002277349258481527, w1=-4.5932924213626054e-05\n",
      "Gradient Descent(13/49): loss=0.42301931548757576, w0=0.00023938893618310144, w1=-4.900318313306638e-05\n",
      "Gradient Descent(14/49): loss=0.4223806759656577, w0=0.0002507062619790494, w1=-5.2164890817577416e-05\n",
      "Gradient Descent(15/49): loss=0.42178887555037825, w0=0.0002613286887962905, w1=-5.522401654907175e-05\n",
      "Gradient Descent(16/49): loss=0.42123846301759116, w0=0.0002715623639408067, w1=-5.832165680570171e-05\n",
      "Gradient Descent(17/49): loss=0.42072509010349285, w0=0.00028123187875117215, w1=-6.135743289792244e-05\n",
      "Gradient Descent(18/49): loss=0.4202451348565581, w0=0.00029050602047288776, w1=-6.440487107406158e-05\n",
      "Gradient Descent(19/49): loss=0.4197954872779463, w0=0.0002993031278486247, w1=-6.741216938385442e-05\n",
      "Gradient Descent(20/49): loss=0.4193734222616614, w0=0.0003077196606539431, w1=-7.041776390464213e-05\n",
      "Gradient Descent(21/49): loss=0.41897652026518495, w0=0.00031572163662109203, w1=-7.3395039143172e-05\n",
      "Gradient Descent(22/49): loss=0.41860261468418974, w0=0.0003233670725421897, w1=-7.636419877892182e-05\n",
      "Gradient Descent(23/49): loss=0.41824975464684355, w0=0.0003306458801864166, w1=-7.931167698986282e-05\n",
      "Gradient Descent(24/49): loss=0.4179161770866755, w0=0.00033759532982607693, w1=-8.224819533455055e-05\n",
      "Gradient Descent(25/49): loss=0.4176002846872414, w0=0.0003442169859205651, w1=-8.51669408463624e-05\n",
      "Gradient Descent(26/49): loss=0.4173006277592129, w0=0.0003505366495202689, w1=-8.807369563162484e-05\n",
      "Gradient Descent(27/49): loss=0.41701588890826147, w0=0.0003565612709453606, w1=-9.096513333985933e-05\n",
      "Gradient Descent(28/49): loss=0.41674486979337083, w0=0.0003623100757512693, w1=-9.38444555829103e-05\n",
      "Gradient Descent(29/49): loss=0.41648647952491813, w0=0.0003677922210238986, w1=-9.67101290109413e-05\n",
      "Gradient Descent(30/49): loss=0.4162397243972803, w0=0.00037302296420328854, w1=-9.956400032029835e-05\n",
      "Gradient Descent(31/49): loss=0.4160036987384184, w0=0.0003780120821868698, w1=-0.00010240545156038199\n",
      "Gradient Descent(32/49): loss=0.41577757671395427, w0=0.00038277227591348604, w1=-0.00010523561180222831\n",
      "Gradient Descent(33/49): loss=0.41556060495935837, w0=0.0003873131730523619, w1=-0.00010805432426595745\n",
      "Gradient Descent(34/49): loss=0.4153520959386416, w0=0.00039164570154537467, w1=-0.00011086233228739654\n",
      "Gradient Descent(35/49): loss=0.41515142194565746, w0=0.00039577898839557936, w1=-0.00011365970564501198\n",
      "Gradient Descent(36/49): loss=0.4149580096773226, w0=0.00039972263983438717, w1=-0.00011644697524548744\n",
      "Gradient Descent(37/49): loss=0.41477133531821525, w0=0.0004034851417640421, w1=-0.000119224316695545\n",
      "Gradient Descent(38/49): loss=0.4145909200840676, w0=0.0004070750523455818, w1=-0.00012199213939390796\n",
      "Gradient Descent(39/49): loss=0.414416326178203, w0=0.00041050018063286186, w1=-0.00012475066306326355\n",
      "Gradient Descent(40/49): loss=0.41424715312039023, w0=0.00041376821372711496, w1=-0.00012750022368189645\n",
      "Gradient Descent(41/49): loss=0.4140830344121428, w0=0.00041688629831349673, w1=-0.0001302410539281108\n",
      "Gradient Descent(42/49): loss=0.4139236345063903, w0=0.0004198613734979856, w1=-0.00013297344214548086\n",
      "Gradient Descent(43/49): loss=0.4137686460528131, w0=0.0004226999606150509, w1=-0.00013569761859298096\n",
      "Gradient Descent(44/49): loss=0.4136177873930536, w0=0.00042540834256138746, w1=-0.00013841383812449113\n",
      "Gradient Descent(45/49): loss=0.4134708002826022, w0=0.0004279924609740882, w1=-0.0001411223213324879\n",
      "Gradient Descent(46/49): loss=0.4133274478184245, w0=0.0004304580152340679, w1=-0.0001438232976235342\n",
      "Gradient Descent(47/49): loss=0.4131875125534187, w0=0.0004328104147386367, w1=-0.00014651697483539594\n",
      "Gradient Descent(48/49): loss=0.41305079478059653, w0=0.0004350548356282444, w1=-0.000149203561746063\n",
      "Gradient Descent(49/49): loss=0.41291711097149886, w0=0.0004371962010974602, w1=-0.00015188325245443622\n"
     ]
    }
   ],
   "source": [
    "# Linear regression using gradient descent\n",
    "\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "max_iters = 50\n",
    "gamma = 3e-7\n",
    "\n",
    "weights, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares regression using normal equation\n",
    "weight, loss = least_squares(y, tX)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression using normal equations\n",
    "lambda_ = 1e-3\n",
    "weight, loss = ridge_regression(y, tX, lambda_)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "af60c6d1ba22fcf692506d80c930cf10d4343429c429540daec4a37d3dd3684b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
